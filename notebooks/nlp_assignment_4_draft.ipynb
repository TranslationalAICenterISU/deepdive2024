{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1o-gdKcMER-3mm1O4ptFLYwomVCySzDXp","timestamp":1690777005057}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"6260f3a4507240649fa06f350fb2ee29":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4867cbaf5510426ba37d44a3751acd1b","IPY_MODEL_f5f4a5f2b4f44da092208f07296abf65","IPY_MODEL_6e8e6ca1ad344ddf8b559314185496dc"],"layout":"IPY_MODEL_e63839891f2845d2ad5c6a7815baafbe"}},"4867cbaf5510426ba37d44a3751acd1b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d5abad3422b4bfab14941309155666e","placeholder":"​","style":"IPY_MODEL_08ea3c3b477543ee986f3cd391e38acd","value":"Downloading (…)lve/main/config.json: 100%"}},"f5f4a5f2b4f44da092208f07296abf65":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e906405f0ad24f90808f9ab4aa831566","max":665,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fd71d86d342a4ae48437f7c04bd08ef6","value":665}},"6e8e6ca1ad344ddf8b559314185496dc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_70d66c8e089b46a499923acb01f05583","placeholder":"​","style":"IPY_MODEL_8b34926a59564f79b8f78fcb1434a446","value":" 665/665 [00:00&lt;00:00, 25.6kB/s]"}},"e63839891f2845d2ad5c6a7815baafbe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d5abad3422b4bfab14941309155666e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08ea3c3b477543ee986f3cd391e38acd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e906405f0ad24f90808f9ab4aa831566":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd71d86d342a4ae48437f7c04bd08ef6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"70d66c8e089b46a499923acb01f05583":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b34926a59564f79b8f78fcb1434a446":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6178a4e3eec547928b24bfb582f5a80f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_718a2589cd504eb5b95341ff8c19c548","IPY_MODEL_6c35f6b4ae39482391ddb8b33cdd68de","IPY_MODEL_7a5f316337f8465e943aa43d9a0f7b24"],"layout":"IPY_MODEL_c625e38555a34d57a45f0155b9370d54"}},"718a2589cd504eb5b95341ff8c19c548":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fae65f9f83b34cda98cfc1d04791327e","placeholder":"​","style":"IPY_MODEL_12e78e785d4d4982836b3fd1572b69a5","value":"Downloading model.safetensors: 100%"}},"6c35f6b4ae39482391ddb8b33cdd68de":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4ee9eb386ade4b2881f1fd34fefc8f53","max":548105171,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1378bfb54dec4cc49689dac27d3a8a44","value":548105171}},"7a5f316337f8465e943aa43d9a0f7b24":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a3e62d2d7d8444fa21320a5fc7487cf","placeholder":"​","style":"IPY_MODEL_4333399e94254543be4041667402de16","value":" 548M/548M [00:09&lt;00:00, 52.9MB/s]"}},"c625e38555a34d57a45f0155b9370d54":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fae65f9f83b34cda98cfc1d04791327e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12e78e785d4d4982836b3fd1572b69a5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4ee9eb386ade4b2881f1fd34fefc8f53":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1378bfb54dec4cc49689dac27d3a8a44":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5a3e62d2d7d8444fa21320a5fc7487cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4333399e94254543be4041667402de16":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1cf2f93ebc45463ba4d656252aefa165":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c13dade151c04fc6b5ffbf7afe33c7ab","IPY_MODEL_051b5fb0a80c4f4088f9535e40414475","IPY_MODEL_d9ad602dcc8346e391be02bc69be48ae"],"layout":"IPY_MODEL_1c4fcbe72f8141d492977b46b67b8e84"}},"c13dade151c04fc6b5ffbf7afe33c7ab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e705868288de40e48838e2b4d7e771de","placeholder":"​","style":"IPY_MODEL_61a06f5721254c5cb010c91dc245c872","value":"Downloading (…)neration_config.json: 100%"}},"051b5fb0a80c4f4088f9535e40414475":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_46749409e8684122a5cbe42c8cc30b7a","max":124,"min":0,"orientation":"horizontal","style":"IPY_MODEL_40926f8e15a349679443027ad24de9ab","value":124}},"d9ad602dcc8346e391be02bc69be48ae":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_090ba415a16b40bcb28834afdaa22db1","placeholder":"​","style":"IPY_MODEL_07d077620d0641afbdc40904b3c4b128","value":" 124/124 [00:00&lt;00:00, 5.48kB/s]"}},"1c4fcbe72f8141d492977b46b67b8e84":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e705868288de40e48838e2b4d7e771de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61a06f5721254c5cb010c91dc245c872":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"46749409e8684122a5cbe42c8cc30b7a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40926f8e15a349679443027ad24de9ab":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"090ba415a16b40bcb28834afdaa22db1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07d077620d0641afbdc40904b3c4b128":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b1615a733d064daca950011a4ee9dbbf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0aef2a564bf9495d8567ae5c4b2a9de0","IPY_MODEL_aae24435e03a47318b913049c75fa441","IPY_MODEL_c5e162974904483ebe734c35f50616c5"],"layout":"IPY_MODEL_c3d894293d1b4963b5fed497ed682629"}},"0aef2a564bf9495d8567ae5c4b2a9de0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f5e254f15dc94976938c0c02d9eed240","placeholder":"​","style":"IPY_MODEL_7e26ebd938964a55a7f5f4e6141f227d","value":"Downloading (…)olve/main/vocab.json: 100%"}},"aae24435e03a47318b913049c75fa441":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6bc91bf1ed754338967ce7bfdc9e525a","max":1042301,"min":0,"orientation":"horizontal","style":"IPY_MODEL_54a9cda48ead4503b49db735f1c081b6","value":1042301}},"c5e162974904483ebe734c35f50616c5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_54ac633e12d8439a9ec8b94db8ede36d","placeholder":"​","style":"IPY_MODEL_4c2b1978f1864a71a09d21c1beefacb0","value":" 1.04M/1.04M [00:00&lt;00:00, 13.9MB/s]"}},"c3d894293d1b4963b5fed497ed682629":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5e254f15dc94976938c0c02d9eed240":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e26ebd938964a55a7f5f4e6141f227d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6bc91bf1ed754338967ce7bfdc9e525a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"54a9cda48ead4503b49db735f1c081b6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"54ac633e12d8439a9ec8b94db8ede36d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c2b1978f1864a71a09d21c1beefacb0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5e330d7f50194645bc51eb9aa103e20b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7151a299ecd54cc09d57189269365794","IPY_MODEL_3cb9a815f83848e18a964eedbbea1b02","IPY_MODEL_f54b5c49273f48b1a21fc74dad175580"],"layout":"IPY_MODEL_3ade4180154445d1b052f03e017e350f"}},"7151a299ecd54cc09d57189269365794":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_680d6dd6b085447dbfd854c6945c7716","placeholder":"​","style":"IPY_MODEL_eadbc255c92f4a41813500b809cd97ce","value":"Downloading (…)olve/main/merges.txt: 100%"}},"3cb9a815f83848e18a964eedbbea1b02":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8356c0e581f14c3f93140939ff5c2fdd","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7f4cf0f5b7ba4300a241ba48e94aa954","value":456318}},"f54b5c49273f48b1a21fc74dad175580":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_960b79a8ff6a451596ab0a3eb445acc5","placeholder":"​","style":"IPY_MODEL_0e4a52d4988242b29bb002dd19828a9a","value":" 456k/456k [00:00&lt;00:00, 3.41MB/s]"}},"3ade4180154445d1b052f03e017e350f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"680d6dd6b085447dbfd854c6945c7716":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eadbc255c92f4a41813500b809cd97ce":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8356c0e581f14c3f93140939ff5c2fdd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f4cf0f5b7ba4300a241ba48e94aa954":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"960b79a8ff6a451596ab0a3eb445acc5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e4a52d4988242b29bb002dd19828a9a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ce5183c565cb402fa066e24c9beccc0c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7e78ce1f088f47b393f3fdc8754d9643","IPY_MODEL_2d1f664fdafa4c708489fcdc1101a2b6","IPY_MODEL_56475d7f4d504e9386d9da821d1f4eba"],"layout":"IPY_MODEL_33075c59e5044e9fad43c140b9be198c"}},"7e78ce1f088f47b393f3fdc8754d9643":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_004266ff59eb4167b1a5a481f0934f99","placeholder":"​","style":"IPY_MODEL_9cd4c26fd23744c3a79b16d11c0c655d","value":"Downloading (…)/main/tokenizer.json: 100%"}},"2d1f664fdafa4c708489fcdc1101a2b6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c48ed659347b4c179d65fa57fc2a2cf0","max":1355256,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8b2fa6e44485450d87270cf0bd32b8e0","value":1355256}},"56475d7f4d504e9386d9da821d1f4eba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dad2d2d6c17a4895ab9accd42877681b","placeholder":"​","style":"IPY_MODEL_fa9a087fd4a142159192fa9e8896174f","value":" 1.36M/1.36M [00:00&lt;00:00, 6.90MB/s]"}},"33075c59e5044e9fad43c140b9be198c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"004266ff59eb4167b1a5a481f0934f99":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9cd4c26fd23744c3a79b16d11c0c655d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c48ed659347b4c179d65fa57fc2a2cf0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b2fa6e44485450d87270cf0bd32b8e0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dad2d2d6c17a4895ab9accd42877681b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa9a087fd4a142159192fa9e8896174f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Text Generation"],"metadata":{"id":"JZ8_Cp_8tNpG"}},{"cell_type":"markdown","metadata":{"id":"18514315-fde"},"source":["To install the necessary dependencies for this code, run the following command:\n","\n","```python\n","!pip install datasets evaluate transformers[torch] rich\n","```\n","\n","This command installs the required packages for working with datasets, performing evaluations, using transformers with PyTorch, and utilizing the rich library.\n","\n","By executing this command, you ensure that all the necessary modules are available for running the code successfully.\n","\n","Make sure to run this command before running any other code that depends on these packages, to avoid import errors or missing dependencies.\n","\n","Note that the exclamation mark at the beginning of the command specifies that it should be executed as a shell command rather than a Python statement."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a08Pv8AZh48w","outputId":"c36b284b-e871-4aef-ab49-21991509ee4e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.14.1)\n","Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.0)\n","Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.31.0)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (13.4.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.3.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.16.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.18.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.12.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2022.10.31)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.13.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.3.1)\n","Requirement already satisfied: torch!=1.12.0,>=1.9 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.0.1+cu118)\n","Requirement already satisfied: accelerate>=0.20.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.21.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich) (2.14.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.5)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.7.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich) (0.1.2)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.9->transformers[torch]) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.9->transformers[torch]) (16.0.6)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.9->transformers[torch]) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.9->transformers[torch]) (1.3.0)\n"]}],"source":["!pip install datasets evaluate transformers[torch] rich"]},{"cell_type":"markdown","metadata":{"id":"f7cf5719-113"},"source":["The `transformers` module is imported, which allows for the usage of pre-trained models in natural language processing tasks.\n","The `pipeline` function from the `transformers` module is imported, which enables the creation of a pipeline of tasks such as text classification or named entity recognition.\n","The `print` function from the `rich` module is imported, which provides enhanced formatting options when printing output to the console.\n","The `pprint` function from the `rich.pretty` module is imported, which enables pretty-printing of Python objects with enhanced formatting.\n","\n","References - https://huggingface.co/blog/how-to-generate"]},{"cell_type":"code","source":["from transformers import pipeline\n","from rich import print\n","from rich.pretty import pprint"],"metadata":{"id":"UwIt_HXxiDVR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"222e16cd-589"},"source":["The code utilizes the GPT-2 language model to generate text.\n","A pipeline object is created with the 'text-generation' task and the 'gpt2' model.\n","The generator is then used to generate text by passing the input prompt \"Hello, I'm a language model\".\n","The generated text is stored in the output variable.\n","Finally, the generated text is printed to the console."]},{"cell_type":"code","source":["generator = pipeline('text-generation', model = 'gpt2')\n","output = generator(\"Hello, I'm a language model\")\n","print(output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":434,"referenced_widgets":["6260f3a4507240649fa06f350fb2ee29","4867cbaf5510426ba37d44a3751acd1b","f5f4a5f2b4f44da092208f07296abf65","6e8e6ca1ad344ddf8b559314185496dc","e63839891f2845d2ad5c6a7815baafbe","3d5abad3422b4bfab14941309155666e","08ea3c3b477543ee986f3cd391e38acd","e906405f0ad24f90808f9ab4aa831566","fd71d86d342a4ae48437f7c04bd08ef6","70d66c8e089b46a499923acb01f05583","8b34926a59564f79b8f78fcb1434a446","6178a4e3eec547928b24bfb582f5a80f","718a2589cd504eb5b95341ff8c19c548","6c35f6b4ae39482391ddb8b33cdd68de","7a5f316337f8465e943aa43d9a0f7b24","c625e38555a34d57a45f0155b9370d54","fae65f9f83b34cda98cfc1d04791327e","12e78e785d4d4982836b3fd1572b69a5","4ee9eb386ade4b2881f1fd34fefc8f53","1378bfb54dec4cc49689dac27d3a8a44","5a3e62d2d7d8444fa21320a5fc7487cf","4333399e94254543be4041667402de16","1cf2f93ebc45463ba4d656252aefa165","c13dade151c04fc6b5ffbf7afe33c7ab","051b5fb0a80c4f4088f9535e40414475","d9ad602dcc8346e391be02bc69be48ae","1c4fcbe72f8141d492977b46b67b8e84","e705868288de40e48838e2b4d7e771de","61a06f5721254c5cb010c91dc245c872","46749409e8684122a5cbe42c8cc30b7a","40926f8e15a349679443027ad24de9ab","090ba415a16b40bcb28834afdaa22db1","07d077620d0641afbdc40904b3c4b128","b1615a733d064daca950011a4ee9dbbf","0aef2a564bf9495d8567ae5c4b2a9de0","aae24435e03a47318b913049c75fa441","c5e162974904483ebe734c35f50616c5","c3d894293d1b4963b5fed497ed682629","f5e254f15dc94976938c0c02d9eed240","7e26ebd938964a55a7f5f4e6141f227d","6bc91bf1ed754338967ce7bfdc9e525a","54a9cda48ead4503b49db735f1c081b6","54ac633e12d8439a9ec8b94db8ede36d","4c2b1978f1864a71a09d21c1beefacb0","5e330d7f50194645bc51eb9aa103e20b","7151a299ecd54cc09d57189269365794","3cb9a815f83848e18a964eedbbea1b02","f54b5c49273f48b1a21fc74dad175580","3ade4180154445d1b052f03e017e350f","680d6dd6b085447dbfd854c6945c7716","eadbc255c92f4a41813500b809cd97ce","8356c0e581f14c3f93140939ff5c2fdd","7f4cf0f5b7ba4300a241ba48e94aa954","960b79a8ff6a451596ab0a3eb445acc5","0e4a52d4988242b29bb002dd19828a9a","ce5183c565cb402fa066e24c9beccc0c","7e78ce1f088f47b393f3fdc8754d9643","2d1f664fdafa4c708489fcdc1101a2b6","56475d7f4d504e9386d9da821d1f4eba","33075c59e5044e9fad43c140b9be198c","004266ff59eb4167b1a5a481f0934f99","9cd4c26fd23744c3a79b16d11c0c655d","c48ed659347b4c179d65fa57fc2a2cf0","8b2fa6e44485450d87270cf0bd32b8e0","dad2d2d6c17a4895ab9accd42877681b","fa9a087fd4a142159192fa9e8896174f"]},"id":"A6Cce_NWi9vx","outputId":"7b0325f3-cf7d-4395-d57c-450e68c458e0"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6260f3a4507240649fa06f350fb2ee29"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6178a4e3eec547928b24bfb582f5a80f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1cf2f93ebc45463ba4d656252aefa165"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1615a733d064daca950011a4ee9dbbf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e330d7f50194645bc51eb9aa103e20b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce5183c565cb402fa066e24c9beccc0c"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n","pip install xformers.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1369: UserWarning: Using `max_length`'s default (50) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1m[\u001b[0m\n","    \u001b[1m{\u001b[0m\n","        \u001b[32m'generated_text'\u001b[0m: \u001b[32m\"Hello, I'm a language model.\\n\\nAnd this might sound like a trivial concept to a person \u001b[0m\n","\u001b[32mwho has never heard the word nanny or nanny girl. But this is an entirely different category.\\n\\nA word model can \u001b[0m\n","\u001b[32mbe any\"\u001b[0m\n","    \u001b[1m}\u001b[0m\n","\u001b[1m]\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n","    <span style=\"font-weight: bold\">{</span>\n","        <span style=\"color: #008000; text-decoration-color: #008000\">'generated_text'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Hello, I'm a language model.\\n\\nAnd this might sound like a trivial concept to a person </span>\n","<span style=\"color: #008000; text-decoration-color: #008000\">who has never heard the word nanny or nanny girl. But this is an entirely different category.\\n\\nA word model can </span>\n","<span style=\"color: #008000; text-decoration-color: #008000\">be any\"</span>\n","    <span style=\"font-weight: bold\">}</span>\n","<span style=\"font-weight: bold\">]</span>\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"7b186def-51a"},"source":["The code imports the necessary modules for working with transformers and PyTorch.\n","\n","The variable `torch_device` is assigned the value \"cuda\" if a GPU is available, otherwise it is assigned the value \"cpu\".\n","\n","The `AutoTokenizer` class from the transformers library is used to create a tokenizer object, which is initialized with the \"gpt2\" model.\n","\n","The `pad_token_id` parameter is set to the eos_token_id of the tokenizer in order to add the EOS token as a PAD token, which helps avoid warnings during model training.\n","\n","The `AutoModelForCausalLM` class is used to create a model object, which is initialized with the \"gpt2\" model and the pad_token_id. The model is then moved to the specified torch_device."]},{"cell_type":"code","source":["from transformers import AutoModelForCausalLM, AutoTokenizer\n","import torch\n","\n","torch_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n","\n","# add the EOS token as PAD token to avoid warnings\n","model = AutoModelForCausalLM.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id).to(torch_device)"],"metadata":{"id":"lqikRaUUjwZu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0a8e8afc-bde"},"source":["The `model_inputs` variable is used to tokenize the given sentence using the tokenizer specified. The input sentence is \"I enjoy walking with my cute dog\". The tokenizer returns a tensor representation of the tokens. The `return_tensors='pt'` argument specifies that the tokenizer should return PyTorch tensors. The resulting tensor is then moved to the specified `torch_device` for further processing."]},{"cell_type":"code","source":["model_inputs = tokenizer('I enjoy walking with my cute dog', return_tensors='pt').to(torch_device)"],"metadata":{"id":"x2xPyWXIkwB7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f00ebd61-bc4"},"source":["The `print(model_inputs[\"input_ids\"])` statement prints the value of the \"input_ids\" key in the `model_inputs` dictionary.\n","\n","The `tokenizer.decode(model_inputs[\"input_ids\"][0])` statement decodes the first element of the \"input_ids\" list using the tokenizer object.\n","\n","The code can be used to inspect the \"input_ids\" values in the `model_inputs` dictionary.\n","\n","The output of the first statement is a list of \"input_ids\" values.\n","\n","The output of the second statement is the decoded value of the first \"input_ids\" element."]},{"cell_type":"code","source":["print(model_inputs[\"input_ids\"])\n","print(tokenizer.decode(model_inputs[\"input_ids\"][0]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":50},"id":"-SnTMZB2k3p9","outputId":"da868ae6-ab32-4ee3-8744-2d93ee75f60b"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m   \u001b[1;36m40\u001b[0m,  \u001b[1;36m2883\u001b[0m,  \u001b[1;36m6155\u001b[0m,   \u001b[1;36m351\u001b[0m,   \u001b[1;36m616\u001b[0m, \u001b[1;36m13779\u001b[0m,  \u001b[1;36m3290\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">40</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2883</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6155</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">351</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">616</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13779</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3290</span><span style=\"font-weight: bold\">]])</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["I enjoy walking with my cute dog\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">I enjoy walking with my cute dog\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"672fb367-acf"},"source":["The `generate` method of the `model` object is used to generate output based on the given input. It takes in `model_inputs` as the parameter, which should be a dictionary containing the necessary inputs for the model. Additionally, the `max_new_tokens` parameter is set to 40, which specifies the maximum number of tokens that should be generated in the output.\n","\n","The generated output is stored in the `greedy_output` variable. This output is generated using a greedy algorithm, which means that at each step, the model selects the token with the highest probability and appends it to the output sequence.\n","\n","The `generate` method is commonly used in natural language processing tasks such as text generation, summarization, and dialogue systems. It leverages the power of pre-trained models to generate human-like text based on the given input.\n","\n","It is important to note that the performance and quality of the generated output may vary depending on the specific model being used, the quality of the input, and other factors such as the training data and parameters used during training. Therefore, it is recommended to experiment with different inputs and parameters to achieve the desired output."]},{"cell_type":"code","source":["greedy_output = model.generate(**model_inputs, max_new_tokens=40)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O2IOQHRPk4zl","outputId":"ab63ddce-991b-48d4-e688-c30ceca7e7f6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1270: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n","  warnings.warn(\n"]}]},{"cell_type":"markdown","metadata":{"id":"20abeac0-f87"},"source":["The `greedy_output` is a function that takes in no arguments.\n","It returns a list of strings, representing the output of a greedy algorithm.\n","The greedy algorithm is used to solve a specific problem, but the details of the problem are not specified in the code.\n","The function does not modify any external variables or objects.\n","The time complexity of the `greedy_output` function is not provided in the code."]},{"cell_type":"code","source":["greedy_output"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TSMVqYrtnMua","outputId":"90028878-27ad-4e6d-85af-750588487f19"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[   40,  2883,  6155,   351,   616, 13779,  3290,    11,   475,   314,\n","          1101,   407,  1654,   611,   314,  1183,  1683,   307,  1498,   284,\n","          2513,   351,   616,  3290,    13,   314,  1101,   407,  1654,   611,\n","           314,  1183,  1683,   307,  1498,   284,  2513,   351,   616,  3290,\n","            13,   198,   198,    40,  1101,   407,  1654]])"]},"metadata":{},"execution_count":44}]},{"cell_type":"markdown","metadata":{"id":"8f18d633-a59"},"source":["The `tokenizer.decode()` function is used to decode the output of the `greedy_output` variable.\n","\n","It takes the first element of the `greedy_output` list and decodes it using the tokenizer.\n","\n","The decoded output is then printed out using the `print()` function.\n","\n","This code snippet assumes that the `tokenizer` and `greedy_output` variables have been defined earlier in the code.\n","\n","The purpose of this code is to display the decoded output of the `greedy_output` using the specified tokenizer."]},{"cell_type":"code","source":["print(tokenizer.decode(greedy_output[0]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":83},"id":"Nj--jqh3lR6e","outputId":"ef511ff5-d398-49d5-e75b-3d01ed2a0caa"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with my dog. I'm not sure if I'll \n","ever be able to walk with my dog.\n","\n","I'm not sure\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with my dog. I'm not sure if I'll \n","ever be able to walk with my dog.\n","\n","I'm not sure\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"9bd452f2-81f"},"source":["The `beam_output` variable is assigned the result of calling the `generate` method on the `model` object. The method takes in `model_inputs`, which are additional arguments passed to the `generate` method. The `max_new_tokens` argument specifies the maximum number of tokens that the model can generate. The `num_beams` argument determines the number of beams to use in the beam search algorithm. The `early_stopping` argument is a boolean value that determines if the generation process should stop when the model predicts an end-of-sentence token.\n","\n","After generating the output, the code prints a separator line consisting of 100 dashes. The `tokenizer.decode` method is then called on `beam_output[0]` to convert the generated tokens back into a human-readable string. The `skip_special_tokens=True` argument is used to exclude any special tokens, such as padding or end-of-sentence tokens, from the decoded output. The resulting string is then printed as the final output."]},{"cell_type":"code","source":["beam_output = model.generate(\n","    **model_inputs,\n","    max_new_tokens=40,\n","    num_beams=5,\n","    early_stopping=True\n",")\n","\n","print(\"Output:\\n\" + 100 * '-')\n","print(tokenizer.decode(beam_output[0], skip_special_tokens=True))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":100},"id":"fYkmQdLcrESQ","outputId":"c8cfa742-f1db-4f91-cf2d-ff7e7bbaa302"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Output:\n","----------------------------------------------------------------------------------------------------\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Output:\n","----------------------------------------------------------------------------------------------------\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.\n","\n","I'm not sure if I'll ever be able to walk with him again. I'm not sure\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.\n","\n","I'm not sure if I'll ever be able to walk with him again. I'm not sure\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"2b03b14f-cc1"},"source":["The `model.generate()` function is used to generate text output using the trained model. It takes in several arguments:\n","\n","- `model_inputs`: This argument contains the inputs to the model, which are passed as keyword arguments. The specific inputs required depend on the model architecture and task.\n","\n","- `max_new_tokens`: This argument specifies the maximum number of new tokens that can be generated by the model.\n","\n","- `num_beams`: This argument determines the number of beams to use during beam search decoding. Each beam represents a possible sequence of generated tokens.\n","\n","- `no_repeat_ngram_size`: This argument specifies the size of n-grams that should not be repeated in the generated output. This helps to prevent the model from generating repetitive sequences.\n","\n","- `early_stopping`: This argument enables or disables early stopping during decoding. If set to True, the decoding process will stop when all beams have reached the end token.\n","\n","The generated output is then printed using the `print()` function. The `tokenizer.decode()` function is used to convert the token IDs in `beam_output` to human-readable text by skipping special tokens."]},{"cell_type":"code","source":["beam_output = model.generate(\n","    **model_inputs,\n","    max_new_tokens=40,\n","    num_beams=5,\n","    no_repeat_ngram_size=2,\n","    early_stopping=True\n",")\n","\n","print(\"Output:\\n\" + 100 * '-')\n","print(tokenizer.decode(beam_output[0], skip_special_tokens=True))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":100},"id":"HcxC8FZFrFEP","outputId":"166ff3f2-212f-4695-da83-a6250418d2cc"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Output:\n","----------------------------------------------------------------------------------------------------\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Output:\n","----------------------------------------------------------------------------------------------------\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.\n","\n","I've been thinking about this for a while now, and I think it's time for me to\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.\n","\n","I've been thinking about this for a while now, and I think it's time for me to\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"markdown","source":["Nice, that looks much better! We can see that the repetition does not appear anymore. Nevertheless, n-gram penalties have to be used with care. An article generated about the city New York should not use a 2-gram penalty or otherwise, the name of the city would only appear once in the whole text!"],"metadata":{"id":"VI0dGam9shAt"}},{"cell_type":"markdown","metadata":{"id":"8f57643c-166"},"source":["The `model.generate()` function is used to generate text outputs using a language model. It takes several arguments:\n","\n","- `model_inputs`: This is a placeholder for the inputs to the model. It should be replaced with the actual inputs you want to generate text for.\n","- `max_new_tokens`: This argument determines the maximum number of new tokens that can be generated in the output text. In this case, it is set to 40.\n","- `num_beams`: This argument determines the number of beams to use in beam search. Beam search is a technique used to generate multiple potential outputs and select the most likely one. Here, 5 beams are used.\n","- `no_repeat_ngram_size`: This argument determines the size of n-grams that should not be repeated in the output text. In this case, n-grams of size 2 are not allowed to repeat.\n","- `num_return_sequences`: This argument determines the number of different sequences to be returned. In this case, 5 sequences are returned.\n","- `early_stopping`: This argument determines whether to stop generation when all beams have finished or not. If set to True, generation will stop when all beams have reached the end of the sequence.\n","\n","After generating the outputs, the code prints each output sequence"]},{"cell_type":"code","source":["beam_outputs = model.generate(\n","    **model_inputs,\n","    max_new_tokens=40,\n","    num_beams=5,\n","    no_repeat_ngram_size=2,\n","    num_return_sequences=5,\n","    early_stopping=True\n",")\n","\n","print(\"Output:\\n\" + 100 * '-')\n","for i, beam_output in enumerate(beam_outputs):\n","  print(\"{}: {}\".format(i, tokenizer.decode(beam_output, skip_special_tokens=True)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":298},"id":"q3wkrth2r2GZ","outputId":"b8062cc6-5074-43f0-def3-e60890f2da7d"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Output:\n","----------------------------------------------------------------------------------------------------\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Output:\n","----------------------------------------------------------------------------------------------------\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1;36m0\u001b[0m: I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.\n","\n","I've been thinking about this for a while now, and I think it's time for me to\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>: I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.\n","\n","I've been thinking about this for a while now, and I think it's time for me to\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1;36m1\u001b[0m: I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with her again.\n","\n","I've been thinking about this for a while now, and I think it's time for me to\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with her again.\n","\n","I've been thinking about this for a while now, and I think it's time for me to\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1;36m2\u001b[0m: I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.\n","\n","I've been thinking about this for a while now, and I think it's a good idea to\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>: I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.\n","\n","I've been thinking about this for a while now, and I think it's a good idea to\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1;36m3\u001b[0m: I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.\n","\n","I've been thinking about this for a while now, and I think it's time to take a\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>: I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.\n","\n","I've been thinking about this for a while now, and I think it's time to take a\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1;36m4\u001b[0m: I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.\n","\n","I've been thinking about this for a while now, and I think it's a good idea.\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>: I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.\n","\n","I've been thinking about this for a while now, and I think it's a good idea.\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"ae4ab7f5-228"},"source":["The code sets the seed to 42 in order to reproduce the same results. The seed can be changed to get different results.\n","The code then activates sampling and deactivates top_k sampling by setting top_k to 0.\n","The `generate` function is called on the `model` with the specified `model_inputs`, `max_new_tokens`, `do_sample`, and `top_k` parameters.\n","The output of the generation is printed, with the generated text being decoded using the `tokenizer` and skipping any special tokens.\n","The generated text is printed as the output, separated by a line of 100 dashes."]},{"cell_type":"code","source":["# set seed to reproduce results. Feel free to change the seed though to get different results\n","from transformers import set_seed\n","set_seed(42)\n","\n","# activate sampling and deactivate top_k by setting top_k sampling to 0\n","sample_output = model.generate(\n","    **model_inputs,\n","    max_new_tokens=40,\n","    do_sample=True,\n","    top_k=0\n",")\n","\n","print(\"Output:\\n\" + 100 * '-')\n","print(tokenizer.decode(sample_output[0], skip_special_tokens=True))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":83},"id":"wtElBEFHs0c-","outputId":"4d7e6ddb-8e98-4ffe-c0d0-a73fa289a221"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Output:\n","----------------------------------------------------------------------------------------------------\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Output:\n","----------------------------------------------------------------------------------------------------\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["I enjoy walking with my cute dog but what I love about being a dog cat person is being a pet being with people who \n","can treat you. I feel happy to be such a pet person and get to meet so many people. I\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">I enjoy walking with my cute dog but what I love about being a dog cat person is being a pet being with people who \n","can treat you. I feel happy to be such a pet person and get to meet so many people. I\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"b28292f0-823"},"source":["The code sets the seed to 42 in order to reproduce the results. It then uses the `generate` function of the `model` object with certain parameters. The `model_inputs` are passed as arguments, along with `max_new_tokens` set to 40, `do_sample` set to True, `top_k` set to 0, and `temperature` set to 0.7. The `generate` function generates output based on these inputs. Finally, the decoded output is printed after removing any special tokens."]},{"cell_type":"code","source":["# set seed to reproduce results. Feel free to change the seed though to get different results\n","set_seed(42)\n","\n","# use temperature to decrease the sensitivity to low probability candidates\n","sample_output = model.generate(\n","    **model_inputs,\n","    max_new_tokens=40,\n","    do_sample=True,\n","    top_k=0,\n","    temperature=0.7,\n",")\n","\n","print(\"Output:\\n\" + 100 * '-')\n","print(tokenizer.decode(sample_output[0], skip_special_tokens=True))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":116},"id":"k-AEsImkuGXs","outputId":"9cb8db1c-7111-4ce4-d294-9204350fc21e"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Output:\n","----------------------------------------------------------------------------------------------------\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Output:\n","----------------------------------------------------------------------------------------------------\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["I enjoy walking with my cute dog but I also love people being nice. I love being in a party with a group of friends\n","and having the opportunity to see people who are so different from me.\n","\n","I'm not sure if\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">I enjoy walking with my cute dog but I also love people being nice. I love being in a party with a group of friends\n","and having the opportunity to see people who are so different from me.\n","\n","I'm not sure if\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"cd5e8513-c2f"},"source":["The code sets the seed to 42 in order to reproduce the same results. The seed can be changed to get different results.\n","\n","The code then sets the value of top_k to 50. This parameter is used during text generation later on.\n","\n","The model.generate() function is called with model_inputs as the input and several other parameters. These parameters include max_new_tokens set to 40, do_sample set to True, and top_k set to 80.\n","\n","The function generates a sample output based on the provided inputs and parameters.\n","\n","Finally, the output is printed, decoded using the tokenizer, and displayed."]},{"cell_type":"code","source":["# set seed to reproduce results. Feel free to change the seed though to get different results\n","set_seed(42)\n","\n","# set top_k to 50\n","sample_output = model.generate(\n","    **model_inputs,\n","    max_new_tokens=40,\n","    do_sample=True,\n","    top_k=80\n",")\n","\n","print(\"Output:\\n\" + 100 * '-')\n","print(tokenizer.decode(sample_output[0], skip_special_tokens=True))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":83},"id":"Ce-a1Sg4uzHX","outputId":"80b356f3-03bb-4b5b-afeb-f65b2301fc1f"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Output:\n","----------------------------------------------------------------------------------------------------\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Output:\n","----------------------------------------------------------------------------------------------------\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["I enjoy walking with my cute dog but what I love about being a dog cat person is being a pet owner with a good, \n","committed dog. I feel happy to be such a good person and get to meet so many people. I\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">I enjoy walking with my cute dog but what I love about being a dog cat person is being a pet owner with a good, \n","committed dog. I feel happy to be such a good person and get to meet so many people. I\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"a5072f77-9fb"},"source":["The code snippet sets the seed to 42 in order to reproduce the results. The seed can be changed if desired.\n","\n","The `top_k` variable is set to 50. This variable is later used in the `generate` method to limit the number of possible tokens to consider during generation.\n","\n","The `generate` method is called on the `model` object, passing in `model_inputs` as arguments. The method generates a sequence of tokens based on the given inputs. The generated sequence is limited to a maximum of 40 new tokens.\n","\n","The `do_sample` parameter is set to True, allowing the model to randomly select the next token based on the probability distribution of the tokens.\n","\n","The `top_p` parameter is set to 0.92, which controls the cumulative probability of the tokens to consider during generation.\n","\n","The `top_k` parameter is set to 0, meaning no limit is placed on the number of tokens to consider based on their probability.\n","\n","The generated output is then printed, with the special tokens skipped using the `skip_special_tokens=True` argument in the `decode` method."]},{"cell_type":"code","source":["# set seed to reproduce results. Feel free to change the seed though to get different results\n","set_seed(42)\n","\n","# set top_k to 50\n","sample_output = model.generate(\n","    **model_inputs,\n","    max_new_tokens=40,\n","    do_sample=True,\n","    top_p=0.92,\n","    top_k=0\n",")\n","\n","print(\"Output:\\n\" + 100 * '-')\n","print(tokenizer.decode(sample_output[0], skip_special_tokens=True))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":83},"id":"rdOnG-8WxS9O","outputId":"888371d4-b606-4208-f673-3203f9ccbdc2"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Output:\n","----------------------------------------------------------------------------------------------------\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Output:\n","----------------------------------------------------------------------------------------------------\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["I enjoy walking with my cute dog but what I love about being a dog cat person is being a pet being with people who \n","can treat you. I feel happy to be such a pet person and get to meet so many people. I\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">I enjoy walking with my cute dog but what I love about being a dog cat person is being a pet being with people who \n","can treat you. I feel happy to be such a pet person and get to meet so many people. I\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"e197dd7d-f97"},"source":["The code sets the seed to 42 in order to reproduce the same results. You can change the seed value if desired.\n","\n","The variable `sample_output` stores the generated output using the `model.generate` function. It takes in `model_inputs` as its arguments, and sets `max_new_tokens` to 40. The output is generated using sampling with a top-p probability of 0.92 and a top-k value of 50.\n","\n","The code then prints the generated output by decoding `sample_output` using the tokenizer. It skips any special tokens in the output.\n","\n","The output is displayed as a string preceded by a line of 100 dashes."]},{"cell_type":"code","source":["# set seed to reproduce results. Feel free to change the seed though to get different results\n","set_seed(42)\n","\n","# set top_k to 50\n","sample_output = model.generate(\n","    **model_inputs,\n","    max_new_tokens=40,\n","    do_sample=True,\n","    top_p=0.92,\n","    top_k=50\n",")\n","\n","print(\"Output:\\n\" + 100 * '-')\n","print(tokenizer.decode(sample_output[0], skip_special_tokens=True))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67},"id":"HvaA9bTkyjFM","outputId":"47bed827-1963-48d0-8690-ffb2a3592835"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Output:\n","----------------------------------------------------------------------------------------------------\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Output:\n","----------------------------------------------------------------------------------------------------\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["I enjoy walking with my cute dog but sometimes I get nervous when she is around.\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">I enjoy walking with my cute dog but sometimes I get nervous when she is around.\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"code","source":["model_name = 'gpt2'\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","device = 'cuda:0'\n","model = AutoModelForCausalLM.from_pretrained(model_name).to(device)"],"metadata":{"id":"j82dfwsj9hXy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompt = \"\"\"\n","Extract the main person and place from a sentence:\n","\n","###\n","Paul is playing football in New York with Heather.\n","Person: Paul, Place: New York, Person: Heather\n","###\n","Jeff is in a hurry to go to Boston.\n","Person: Jeff, Place: Boston\n","###\n","Max is going to Phildelphia.\n","Person: Max, Place: Philadelphia\n","###\n","Sam is from Phoenix\n","\"\"\""],"metadata":{"id":"4wkZ1h9L9kxG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n","outputs = model.generate(input_ids=input_ids, max_new_tokens=10, temperature=0.01, eos_token_id=tokenizer.encode(\"###\"), pad_token_id = tokenizer.eos_token_id)\n","print(tokenizer.decode(outputs[0][len(input_ids[0]):-1]))"],"metadata":{"id":"w8vbguh_9orF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompt = \"\"\"\n","Extract the sentiment from the text.\n","\n","###\n","The food and service was excellent. 5 stars!\n","Sentiment: Positive\n","###\n","Delicious meals and great ambience, will recommend this place.\n","Sentiment: Positive\n","###\n","Terrible experience. Avoid this restaurant.\n","Sentiment: Negative\n","###\n","Food tasted awful, will not come back again.\n","\"\"\""],"metadata":{"id":"UyUBE1Nk9xD8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n","outputs = model.generate(input_ids=input_ids, max_new_tokens=10, temperature=0.01, eos_token_id=tokenizer.encode(\"###\"), pad_token_id = tokenizer.eos_token_id)\n","print(tokenizer.decode(outputs[0][len(input_ids[0]):-1]))"],"metadata":{"id":"7zQe4m1Z90Kz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForCausalLM\n","import transformers\n","import torch\n","\n","model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n","token = \"<huggingface token>\"\n","model = AutoModelForCausalLM.from_pretrained(model_name,use_auth_token=token)\n","tokenizer = AutoTokenizer.from_pretrained(model_name,use_auth_token=token)\n","\n","pipeline = transformers.pipeline(\n","    \"text-generation\",\n","    model=model,\n","    tokenizer=tokenizer,\n","    torch_dtype=torch.float16,\n","    device_map=\"auto\"\n",")"],"metadata":{"id":"3JdOl36c945j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["B_INST, E_INST = \"[INST]\", \"[/INST]\"\n","B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\""],"metadata":{"id":"QD-ZNKq0-BHk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompt_template = \"\"\"\n","System: {B_SYS} You are a helpful assistant and your name is S2Bot.\n","Given relevant parts of a document and a question, create a final answer.\n","{E_SYS}\n","User:\n","{B_INST}\n","Use the following portion of a long document to see if any of the text is relevant to answer the question. Answer concisely in one sentence.\n","Context:\n","{context}\n","Question:\n","{question}\n","{E_INST}\n","Assistant:\n","\"\"\"\n","context = \"The winners were announced during the awards ceremony on March 12, 2023. \\\n","      Everything Everywhere All at Once became the first science-fiction film to win Best Picture,[10] and it was the third film alongside 1951's A Streetcar Named Desire and 1976's Network to win three acting awards.[11] \\\n","      Best Director winners Daniel Kwan and Daniel Scheinert became the third pair of directors to win for the same film.[a] For the first time since the 7th ceremony in 1935, all five Best Actor nominees were first time nominees.[12] Michelle Yeoh was the first Asian winner for Best Actress and the second woman of color overall after Halle Berry, who won for her performance in 2001's Monster's Ball.[13] Furthermore, she was the first woman to identify as Asian to be nominated in that category.[b] Ke Huy Quan became the first Vietnamese person to win an Oscar and the second Asian winner for Best Supporting Actor after Haing S. Ngor, who won for his role in 1984's The Killing Fields.[15][16].format(context=context,)\"\n","question = \"Who won 2023 oscar?\"\n","prompt = prompt_template.format(B_SYS=B_SYS,context=context,question=question,E_SYS=E_SYS, B_INST=B_INST,E_INST=E_INST)\n","sequences = pipeline(\n","    prompt,\n","    do_sample=True,\n","    temperature=0.6,\n","    top_p = 0.9,\n","    num_return_sequences=1,\n","    eos_token_id=tokenizer.eos_token_id,\n","    max_length=1024,\n",")\n","for seq in sequences:\n","    print(f\"{seq['generated_text']}\")\n"],"metadata":{"id":"I9qTFhuJ-GjP"},"execution_count":null,"outputs":[]}]}